# -*- coding: utf-8 -*-
"""source.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R3SBnz2P5uCMZdc24Oc6ZgbEqeTajQsn

# Projeto Machine Learning Allcart - Product Categorization
Author: Ingrid Cadu<br>
Data: Sept 07, 2022<br>
<br>
The categorization takes the 3 last categories, however the 3rd column is discarted.<br>
E.g.<br>
Beverages › Beverage Syrups & Concentrates › Concentrates<br>
I have token:<br>
Beverages › Beverage Syrups & Concentrates›

# Libraries & Datas
"""

import re
import sys
import warnings
import pandas as pd
import numpy as np
import unicodedata
import html

# Stopwords package
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer

# Split and vectorize them
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

# PERSONAL
url_personal = 'https://media.githubusercontent.com/media/Ingrid-0906/Obiwan_2022/main/CSVFiles/meta_Health_and_Personal_Care.csv' # Check github data link
person = pd.read_csv(url_personal)
person = person.loc[:,['title','categories']]

# Opening data and taking the columns i need to proceed
url_feed_personal = 'https://media.githubusercontent.com/media/Ingrid-0906/Obiwan_2022/main/CSVFiles/metadata_Feeding_PERSONAL_CARE.csv' # Check github raw data link
feed_personal = pd.read_csv(url_feed_personal)

# GROCERY
# Opening data and taking the columns i need to proceed
url_grocery = 'https://media.githubusercontent.com/media/Ingrid-0906/Obiwan_2022/main/CSVFiles/Original_grocery_280k.csv'
grocery = pd.read_csv(url_grocery, dtype={'fit': 'str'})
grocery = grocery.loc[:,['title','category']]

# Opening data and taking the columns i need to proceed
url_feed_grocery = 'https://media.githubusercontent.com/media/Ingrid-0906/Obiwan_2022/main/CSVFiles/metadata_Feeding_GROCERIES.csv'
feed_grocery = pd.read_csv(url_feed_grocery)

"""# Cleaning categories"""

# Splititng the categories into columns
def get_grocery(categ):
  try:
    return ' -> '.join(eval(categ))
  except IndexError: # Error if the outer list is empty
    return 'no_category'
  except TypeError: # Error if the outer list is missing
    return 'no_category'


# Splititng the categories into columns
def get_personal(categ):
  try:
    return ' -> '.join(eval(categ)[0])
  except IndexError: # Error if the outer list is empty
    return 'no_category'
  except TypeError: # Error if the outer list is missing
    return 'no_category'

# Create column for category path
grocery['category_path'] = grocery['category'].apply(get_grocery)
person['category_path'] = person['categories'].apply(get_personal)

# Exclude data where title or category is missing
grocery_0 = grocery[grocery['category_path'] != 'no_category']
person_0 = person[person['category_path'] != 'no_category']

# Splitting into columns
grocery_1 = pd.DataFrame(grocery_0['category_path'].str.split(' -> ').values.tolist())
person_1 = pd.DataFrame(person_0['category_path'].str.split(' -> ').values.tolist())

# Setting product title
grocery_1['title'] = grocery_0['title']
person_1['title'] = person_0['title']

# Dropping the products with les classes
grocery_1 = grocery_1.dropna(subset=['title'], axis=0)
person_1 = person_1.dropna(subset=['title'], axis=0)

"""## Removing categories from grocery data"""

# Removing categories that actually does not exists
grocery_1[2] = grocery_1[2].replace({"20 easy prefilled Easter eggs with 3 candy assortments including Brach's Jellybeans and Chewy Lemonheads":"Candy & Chocolate Gifts",
                           "-Butlers -Creamy Toffees -Contains Milk & Soya & May Contain Traces of Nuts -Bagged, 125g":"Candy & Chocolate Bars",
                           "-The Connemara Kitchen -Coffee Fudge -Tin Package -160g":"Candy & Chocolate"})

# Changing the names accordingly to current year: 2022
grocery_1[2] = grocery_1[2].replace({'Coffee, Tea & Cocoa': grocery_1[3].values})
grocery_1[2] = grocery_1[2].replace({'Cocoa': 'Hot Chocolate & Malted Drinks'})
grocery_1[2] = grocery_1[2].replace({'Ice Cream & Novelties':'Ice Cream & Frozen Novelties'})

# Filling the child category if there is not a class
grocery_1[2] = grocery_1[2].fillna(grocery_1[1])

# Removing categories less than 10 products
counts = grocery_1[2].value_counts()
grocery_1 = grocery_1[~grocery_1[2].isin(counts[counts < 11].index)]

# Reseting index for all dataframe
grocery_1 = grocery_1.reset_index()
grocery_1 = grocery_1.loc[:,['title',1,2]]

"""## Removing category from personal data"""

# Picking out the best categories
person_1 = person_1[person_1[1].isin(['Health Care','Vitamins & Dietary Supplements','Personal Care','Baby & Child Care'])]
person_1 = person_1.loc[:,['title',1,2]]

"""# Feeding data

## Grocery data
"""

# Create column for category path
feed_grocery['category_path'] = feed_grocery['category'].apply(get_grocery)

# Exclude data where title or category is missing
feed_grocery_0 = feed_grocery[feed_grocery['category_path'] != 'no_category']

# Splitting into columns
feed_grocery_1 = pd.DataFrame(feed_grocery_0['category_path'].str.split(' -> ').values.tolist())
feed_grocery_1['title'] = feed_grocery_0['title']

# Dropping the products with les classes -CHANGE HERE AFTER THE SCARPPING!!!
feed_grocery_1 = feed_grocery_1.dropna(subset=['title'], axis=0)
feed_grocery_1 = feed_grocery_1.loc[:,['title',0,1]]

# Renaming cols to match with grocery data
feed_grocery_1 = feed_grocery_1.rename(columns={0:1, 1:2})

# Concating them
GROCERY = pd.concat([grocery_1,feed_grocery_1])

# Changing column 1 / the mother
GROCERY[1] = GROCERY[1].replace({'Breakfast':'Breakfast Foods','Jams, Jellies & Preserves':'Jams, Jellies & Sweet Spreads'})

# Changing column 1 / the child
GROCERY[2] = GROCERY[2].replace({'Jams, Jellies & Sweet Spreads':'Jams, Jellies & Preserves',
                           'Beans':'Beans & Peas',
                           'Peas':'Beans & Peas',
                           'Bubble Tea Kits':'Bubble Tea Tapioca Pearls',
                           'Cheeses':'Cheese',
                           'Cheese Assortments & Samplers':'Cheese',
                           'Dairy & Plant-Based Yogurt':'Yogurt',
                           'Desserts & Bakery':'Desserts',
                           'Baking Syrups, Sugars & Sweeteners':'Syrups, Sugars & Sweeteners',
                           'Beverage Syrups & Concentrates':'Syrups, Sugars & Sweeteners',
                           'Cream Cheeses':'Cream Cheese',
                           'Coconut Milk & Cream':'Milk & Cream'})

# Changing col two
GROCERY[2] = GROCERY[2].replace({'Milks & Cream':'Milk & Cream',
                           'Butter, Margarine & Plant-Based Alternatives':'Butter & Margarine',
                           'Dried Beans, Grains & Rice':'Grains & Rice',
                           'Dried Grains & Rice':'Grains & Rice',
                           'Dried Beans':'Grains & Rice',
                           'Dried Lentils':'Grains & Rice',
                           'Dried Peas':'Grains & Rice',
                           'Packaged Cured & Deli Meats':'Deli',
                           'Dried Fruit & Raisins':'Dried Fruits & Vegetables',
                           'Fruit Compotes':'Fruit & Compotes',
                           'Fruits':'Fruit & Compotes',
                           'Hard Candy':'Hard Candy & Lollipops',
                           'Herb, Spice & Seasoning Gifts':'Herbs, Spices & Seasonings',
                           'Hot Dogs, Links & Sausages':'Hot Dogs & Franks',
                           'Ice Creams & Frozen Novelties':'Ice Cream & Frozen Novelties',
                           'Jelly Beans':'Jelly Beans & Gummy Candy'})

# Changing col two
GROCERY[2] = GROCERY[2].replace({'Juices':'Juice',
                           'Meat Substitute':'Meat Substitutes',
                           'Meatballs, Chunks & Crumbles':'Meats',
                           'Noodle Soups':'Pasta & Noodles',
                           'Asian Noodle Soup':'Pasta & Noddles',
                           'Pork':'Pork Meat',
                           'Sandwich Spreads':'Sandwiches & Wraps',
                           'Frozen Seafood':'Seafood',
                           'Sour Cream':'Sour Creams',
                           'Wasabi Peas':'Wasabi',
                           'Wild Game & Fowl':'Wild Game & Fowl Meat',
                           'Meat, Poultry & Seafood':'Meats',
                           'Meat & Seafood':'Meats',
                           'Sauce, Gravy & Marinade Gifts':'Sauces',
                           'Soda Soft Drinks':'Soft Drinks',
                           'Tea Beverages':'Tea',
                           'Suckers & Lollipops':'Hard Candy & Lollipops',
                           'Soups, Stews & Chili':'Soups',
                           'Soups, Stocks & Broths':'Soups',
                           'Baking Chips':'Baking Chocolates, Carob & Cocoa',
                           'Fresh Baked Cookies':'Grocery Cookies'})

# Removing gifts_1
GROCERY = GROCERY[~GROCERY[2].isin(['Fresh Cut Flowers','Meat & Seafood Gifts','Assortments & Variety Gifts','Food & Beverage Gifts',
                           'Fresh Flowers & Live Indoor Plants','Candy & Chocolate Assortments','Candy & Chocolate Gifts'])]

# Removing gifts_2
GROCERY = GROCERY[~GROCERY[2].isin(['Jam, Jelly & Sweet Spread Gifts','Fruit & Nut Gifts','Fruit & Vegetable Trays',
                          'Fresh Flowers & Live Indoor Plants','Bakery & Dessert Gifts'])]

"""## Personal data"""

# Create column for category path
feed_personal['category_path'] = feed_personal['category'].apply(get_grocery)

# Exclude data where title or category is missing
feed_personal_0 = feed_personal[feed_personal['category_path'] != 'no_category']

# Splitting into columns
feed_personal_1 = pd.DataFrame(feed_personal_0['category_path'].str.split(' -> ').values.tolist())
feed_personal_1['title'] = feed_personal_0['title']

# Dropping nan from all feed data
feed_personal_1 = feed_personal_1.dropna(subset=['title'], axis=0)

# Picking the cols we need and renaming it to march with personal data
feed_personal_1 = feed_personal_1.loc[:,['title',0,1]]
feed_personal_1 = feed_personal_1.rename(columns={0:1, 1:2})

# Linking both datas
PERSONAL = pd.concat([person_1,feed_personal_1])
# Clear null values
PERSONAL = PERSONAL[~PERSONAL[2].isnull()]

PERSONAL[:2]

"""# Saving dataframe"""

# Concat all
STORE = pd.concat([GROCERY,PERSONAL])

# View data
STORE[:2]

# Checking null
STORE.isnull().sum()

# Saving data
STORE.to_csv('metadata_product.csv', index=False)